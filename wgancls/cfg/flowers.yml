CONFIG_NAME: 'WGan-CLS'
DATASET_NAME: 'flowers'

DATASET_DIR: '/share/hipp/Neural_Project/text-to-image-master/data/flowers/'
CHECKPOINT_DIR: '/share/hipp/Neural_Project/text-to-image-master/checkpoints/WGan-CLS/flowers/'
LOGS_DIR: '/share/hipp/Neural_Project/text-to-image-master/logs/WGan-CLS_logs/'
SAMPLE_DIR: '/share/hipp/Neural_Project/text-to-image-master/samples/WGan-CLS/flowers/'

MODEL:
  Z_DIM: 128 # Dimension of the noise vector
  OUTPUT_SIZE: 64 # The ouput size of the image (e.g 64x64)
  EMBED_DIM: 1024 # The dimension of the embedding before compression (as given by the cnn-rnn encoder)
  COMPRESSED_EMBED_DIM: 128 # The dimension of the embedding after compression
  GF_DIM: 128 # The number of filters in the first convolutional layer of the generator
  DF_DIM: 128 # The number of filters in the first convolutional layer of the discriminator
  IMAGE_SHAPE:
    W: 64
    H: 64
    D: 3

TRAIN:
  FLAG: False
  MAX_STEPS: 200000
  BATCH_SIZE: 8 # Size of the training batches
  SAMPLE_NUM: 64 # The number of samples to be generated during training/testing by the sampler network. It must be a perfect square!!!
  D_LR: 0.0001 # Learning rate
  G_LR: 0.0001
  BETA1: 0.0 # Adam beta1
  BETA2: 0.9 # Adam beta2
  SUMMARY_PERIOD: 10
  N_CRITIC: 1
  NUM_EMBEDDINGS: 4
  CHECKPOINTS_TO_KEEP: 3
  SAMPLE_PERIOD: 300
  COEFF:
    KL: 1.0
    LAMBDA: 100.0

EVAL:
  FLAG: False
  INCEP_CHECKPOINT_DIR: /share/hipp/Neural_Project/text-to-image-master/checkpoints/Inception/flowers/
  SAMPLE_SIZE: 1000
  INCEP_BATCH_SIZE: 64
  NUM_CLASSES: 20
  SIZE: 50000
  ACT_STAT_PATH: /share/hipp/Neural_Project/text-to-image-master/data/fid/flowers/stats.npz
  R_IMG_PATH: /share/hipp/Neural_Project/text-to-image-master/data/flowers/jpg
